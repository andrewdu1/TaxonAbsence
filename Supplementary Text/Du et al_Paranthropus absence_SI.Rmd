---
title: "Supplementary text for \"Placing probabilities on a taxon's true absence: applications to the hominin genus *Paranthropus*\"" 
author: "Andrew Du, Eric Friedlander, John Rowan, Zeresenay Alemseged"
output: 
  pdf_document:
      number_sections: true
      toc : true
bibliography: My Library.bib
csl: journal-of-human-evolution.csl
---

```{r, setup, include = FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/adu/OneDrive - Colostate/Desktop/Manuscripts/Du & Alemseged 2019_Paranthropus afar/GitHub/TaxonAbsence/")
```


# Detailed overview of the model

## Motivation

While the methodology presented in this work is broadly applicable to any taxon---regarding the problem of inferring its true absence across a collection of sites---we present the model using the example of the hominin genus *Paranthropus* from eastern Africa, as was done in the main text.
Inferring whether *Paranthropus* was truly absent at a site is difficult because observed absence is consistent with two mutually exclusive outcomes: (A) *Paranthropus* never occupied the site (i.e., true absence), or (B) it did occupy the site but has not been sampled yet. 
We are ultimately interested in estimating the probability of each of these two possibilities, conditional on not finding a *Paranthropus* specimen after sampling $n$ mammalian specimens at a given site. 
To accomplish this, we first fit a zero-inflated beta-binomial model to the data using maximum likelihood estimation. 
This model can be viewed as a mixture model wherein each of the two previously mentioned outcomes is modeled with a different probability distribution called a *mixture component*. 
As we will see, our model, along with Bayes' theorem, will allow us to compute the probability that a given site was generated from possibility (A) or (B), conditional on sampling $n$ mammalian specimens without finding *Paranthropus*, and thus estimate the probability that *Paranthropus* was truly absent from a given site or has not been sampled yet. 


## Derivation

We now present the proposed model. 
In order to instill intuition, we outline the model in a generative fashion (i.e., how data would be generated from the model). 
Let $\psi$ be the probability that a given site belongs to component (B) (i.e., *Paranthropus* is truly present). 
In particular, if one were to select a site uniformly at random with no additional information about the recovered specimens, $\psi$ represents the probability that *Paranthropus* was truly present.
Intuitively, one can think of $\psi$ as the expected proportion of all sites that contains *Paranthropus*, regardless of whether it has been observed yet. 
Thus, there is a single $\psi$ that needs to be specified for the model, which applies across all sites. 
It follows that $1 - \psi$ is the probability that a site belongs to component (A) (i.e., *Paranthropus* was truly absent from the site).

For site $i$, let $Z_i$ be a latent (unobserved) variable that is equal to $1$ if *Paranthropus* was truly present and $0$ otherwise. 
It follows that $P(Z_i = 1) = \psi$ and $P(Z_i = 0) = 1 - \psi$. 
In the language of statistics, we say that $Z_i$ is a $Bernoulli(\psi)$ random variable and write:

\begin{align} 
    Z_i \sim Bernoulli(\psi).  
      \label{bernoulli}
\end{align}

For each value of $Z_i$ (i.e., 0 or 1), we must specify the distribution on the number of *Paranthropus* specimens that will be sampled if $n_i$ total mammalian specimens are collected. 
In general, if we were to know the sampling probability of *Paranthropus*, denoted $p_i$, then the number of sampled *Paranthropus* specimens can be modeled using a $Binomial(n_i, p_i)$ distribution. 
Using an example, a $Binomial(n,p)$ random variable represents the number of heads one may observe if flipping a weighted coin $n$ times, given that the probability of obtaining heads from a single flip is $p$. 
In our setting, if we know that $p_i$ is the probability that a randomly chosen specimen from site $i$ will be *Paranthropus* (i.e., its sampling probability), then the number of *Paranthropus* specimens out of $n_i$ mammalian specimens has a $Binomial(n_i, p_i)$ distribution.

We now use the value of $Z_i$ to generate a value for $p_i$. 
Recall that if $Z_i = 0$, then *Paranthropus* never occupied the $i$th site, so the probability that a sampled mammalian specimen is *Paranthropus* is zero (i.e., $p_i=0$). 
This is the first mixture component in our model, and we say that there is a *point mass* at $0$ because all of the mass of the binomial distribution is concentrated at $0$ (i.e., if $p_i = 0$, then the number of sampled *Paranthropus* specimens must also equal $0$).
If $Z_i = 1$, then *Paranthropus* did occupy the site. 
However, the sampling probability of *Paranthropus* varies from site to site. 
Therefore, we model $p_i$ as a random effect using a one-parameter beta distribution, which has the probability density function $(1 + \lambda) (1 - p_i) ^ {\lambda}$ if $\lambda\geq 0$. 
This beta distribution is simply a reparametrization of the standard beta distribution with parameters $\alpha = 1$ and $\beta = 1 - \lambda$, i.e., $Beta(1, 1 + \lambda)$ (cf. the "Standard Reflected Beta Distribution" from @wang_adaptive_2016). 
The parameter $\lambda$ is the same across all sites, and it determines the shape of the distribution, which in our case ($\lambda \geq 0$) can only be monotonically decreasing. 
This is an appropriate assumption here because such a distribution has the majority of its probability density concentrated towards lower values of $p_i$, reflecting the general ecological pattern that a species is rare, and thus harder to sample, at most sites within its geographic range [@brown_spatial_1995; @murray_species_1999].
As with $\psi$, we estimate $\lambda$ from the data. 
Figure \ref{fig:beta_dist} shows how different values of $\lambda$ affect the shape of the beta distribution.

```{r, echo = FALSE, fig.cap = "Shape of the monotonically decreasing, one-parameter beta distribution under different values of the parameter, $\\lambda$. Larger values of $\\lambda$ generate more sharply decreasing functions. \\label{fig:beta_dist}"}
x <- seq(0, 1, length.out = 1000)

lambda <- seq(0, 10)

plot(1, 
     type = "n", 
     xlim = range(x), 
     ylim = c(0, 11), 
     xlab = expression("Sampling probability (" * italic(p[i]) * ")"), 
     ylab = "Density")

library(RColorBrewer)

colors <- brewer.pal(length(lambda), "Spectral")

for(i in seq_along(lambda)) lines(x, dbeta(x, 1, 1 + lambda[i]), col = colors[i])

legend("topright", legend = lambda, title = expression(lambda), lty = rep(1, length(lambda)), col = colors, cex = 0.85)
```

Combining scenario (A), where *Paranthropus* is truly absent at the $i$th site and $Z_i = 0$, with scenario (B), where *Paranthropus* is truly present at the $i$th site and $Z_i = 1$, we can write the distribution of $p_i$ as: 

\begin{subequations}
  \begin{align} 
      P(p_i=w | Z_i = 0) = \begin{cases} 
        1 & \text{if } w = 0 \\
        0 & \text{otherwise}
     \end{cases}
     \label{pi|Z=0}
  \end{align}
  
  \begin{align} 
      f(p_i | Z_i = 1) = (1 + \lambda) (1 - p_i) ^ {\lambda},\quad \text{ if } \lambda \geq 0,\quad   0 \leq p_i \leq 1.
      \label{pi|Z=1}
  \end{align}
\end{subequations}

Equation \ref{pi|Z=0} can also be expressed more conveniently using an *indicator function*: $P(p_i | Z_i = 0)= I(p_i = 0)$, where $I(p_i = 0)$ equals $1$ if $p_i = 0$ and $0$ otherwise. 

Finally, with $p_i$ defined for each site, we can now model the number of *Paranthropus* specimens recovered at site $i$, denoted $X_i$, as:

\begin{align} 
    X_i \sim Binomial(n_i, p_i)
    \label{binomial}
\end{align}

where $n_i$ is the total number of mammalian specimens recovered at site $i$ and is given by the observed data. 

Since we have now specified the entire generative model, we can use this model to compute the probability of recovering, for any $i$, $X_i$ specimens of *Paranthropus* from the $i$th site. 
First, focus on the case of $Z_i = 0$. 
Recall that if $Z_i=0$, then $p_i = 0$, and our sampling probability becomes a point mass at $0$.
Therefore, the number of sampled *Paranthropus* specimens must also be zero (i.e., $X_i = 0$), so:

\begin{align}
    P(X_i = x | Z_i = 0) = I(x_i = 0).
    \label{X|Z=0}
\end{align}

Alternatively, if $Z_i = 1$, we must account for both the randomness in selecting $p_i$ and the randomness in sampling $X_i$ given $p_i$, making the sampling probability hierarchical. 
Recalling that $p_i$ is distributed according to $Beta(1, 1 + \lambda)$, we have:

\begin{align}
    P(X_i = x | Z_i = 1) \sim Binomial(n_i, p_i), \text{ where } p_i \sim Beta(1, 1 + \lambda).
    \label{X|Z=1}
\end{align}

This commonly used distribution is referred to as the *beta-binomial distribution* and has the following probability mass function (PMF):

\begin{align}
    P(X_i = x | Z_i = 1) = f_B(x_i;n_i,\lambda) = {n_i\choose x_i} \frac{B(x_i + 1, n_i - x_i + 1 + \lambda)}{B(1, 1 + \lambda)},
    \label{beta-binom}
\end{align}

where $B$ denotes the beta function. 

Combining Equations \ref{bernoulli}, \ref{X|Z=0}, and \ref{beta-binom} by adding over the two possible values of the latent variable $Z_i$, the law of total probability implies that:

\begin{equation}
\begin{aligned}
    P(X_i = x) &= P(X_i = x | Z_i = 0) P(Z_i = 0) + P(X_i = x | Z_i = 1) P(Z_i = 1) \\
               &= I(x = 0) (1 - \psi) + f_B(x;n_i,\lambda) \psi.
\end{aligned}
\label{P_X}
\end{equation}

Equation \ref{P_X} is the probability of recovering $x$ number of *Paranthropus* specimens for the $i$th site if the sample size is $n_i$.


\subsection{Estimating model parameters} \label{estim}

```{r, echo = FALSE}
d <- read.csv("Datasets/NISP data.csv", header = TRUE)
```

In the previous section, we discussed how the data are generated by our model, but ultimately, we are interested in going in the opposite direction: that is, given the data, $X_1, X_2,...X_{`r nrow(d)`}$ (where $X_1$ is the number of *Paranthropus* specimens in the first site, $X_2$ is the number of *Paranthropus* specimens in the second site, and we have a total of `r nrow(d)` sites), what are the parameters ($\psi$, $\lambda$)?
Furthermore, we are interested in using these parameter estimates to infer the latent variables $Z_1, Z_2,...,Z_{`r nrow(d)`}$, using data from both within and outside the $i$th site. 
In other words, we would like to assess the probability that a given site has *Paranthropus* truly present or not, conditional on observations from the site and parameter estimates in our model (which are informed by data from all sites).
To estimate the parameters ($\psi$, $\lambda$), we use a method called *maximum likelihood estimation*.
Intuitively, this method selects the parameter values that will make the data most probable, with larger probabilities indicating more likely parameter estimates [@wang_principles_2010]. 
Using the estimated parameter values, data, and Bayes' theorem (see next section), we can estimate the probability that $Z_i = 1$, conditional on the parameter estimates and data, which is the conditional probability that *Paranthropus* was truly present at the site; the complement of this probability is the conditional probability that *Paranthropus* was truly absent from the $i$th site. 
We note that the case that is most interesting is when no *Paranthropus* specimens have yet been observed at the given site (i.e., $X_i = 0$).
To do all this, we operate in the framework of likelihood and define a *likelihood function*.

A likelihood function quantifies information about model parameters that is contained in the data [@wang_adaptive_2016].
It is numerically equivalent to the *joint probability* of the data given the parameters, so to get the likelihood function, we multiply the probability of the data by itself $N$ times, where $N$ is sample size [@wang_principles_2010]: e.g., $L(\psi, \lambda | X) = \prod_{i=1}^{N} P(X_i | \psi, \lambda)$. 
For our study, the probability of the data is given by Equation \ref{P_X}, so our likelihood function is defined as:

\begin{align}
    L(\psi, \lambda | X) = P(X | \psi, \lambda) = \prod_{i=1}^{N} I(x_i = 0)(1 - \psi) + f_B(x_i; n_i, \lambda) \psi.
    \label{likelihood}
\end{align}

We then use the L-BFGS-B optimization algorithm [@byrd_limited_1995] to find the parameter values $(\psi, \lambda)$ that maximize the likelihood function (Equation \ref{likelihood}). In practice, we work with the log transformation of Equation \ref{likelihood} for analytical tractability.


## Bayes' theorem

For this subsection, we first provide a brief introduction to Bayes' theorem and what the equation aims to accomplish, with respect to our research question of interest.
We then show how we use Bayes' theorem to derive our main probability of interest: the probability that *Paranthropus* was truly absent at a given site, conditional on the estimated parameters and data.

### Introduction to Bayes' theorem

In scientific inference, we understand that a process(es) generates a pattern(s) (i.e., data), and we ultimately want to learn something about the generative process from the resulting data.
In Bayesian inference, processes are described with models and their unobserved quantities (e.g., latent variables, parameters), and we learn something about these unobserved quantities of interest from observed data [@hobbs_bayesian_2015].
For example, whether *Paranthropus* was truly absent or present at a given site is an unobserved quantity (i.e., latent variable), and we want to learn something about this latent variable at each site, given the observed data (i.e., sampling $X_i$ number of *Paranthropus* specimens after sampling $n_i$ number of mammalian specimens).
Equations \ref{X|Z=0} and \ref{beta-binom} tell us how the data are generated, given that we know (or assume) the true state of the latent variable at a given site, i.e., $P(X_i|Z_i)$.
However, we want our direction of inference to go in the opposite direction: we want to transpose $P(X_i|Z_i)$ to get $P(Z_i|X_i)$, i.e., we want to infer the latent variable from the observed data.
Bayes' theorem tells us how to transpose conditional probabilities, using the basic algebraic rules of conditional probability:

\begin{equation}
    P(Z_i|X_i) = \frac{P(X_i|Z_i) P(Z_i)}{P(X_i)}.
\label{bayes}
\end{equation}

Thus, based on this transposition of conditional probabilities (Equation \ref{bayes}), Bayes' theorem enables us to infer something about unobserved processes of interest (e.g., latent variables, parameters) from the observed data. 

Explaining each component of Equation \ref{bayes}, $P(Z_i|X_i)$ is the *posterior probability*, $P(X_i|Z_i)$ is the *likelihood*, $P(Z_i)$ is the *prior probability*, and $P(X_i)$ is the *marginal distribution of the data*.
The likelihood connects observed data with unobserved quantities in the model, while the prior probability summarizes what we know about the unobserved quantities before our study is conducted.
For our model, the parameter determining the prior distribution, $\psi$ (Equation \ref{bernoulli}), is estimated from the data, so our model is an empirical Bayes one [@carlin_bayes_2000].
The marginal distribution of the data serves as a normalizing factor, ensuring that the area under the posterior probability curve equals one.
This means that the posterior probability distribution is a true probability density/mass function, and we can apply to it the rules and intuitions associated with probability theory.

### Applying Bayes' theorem to our research question

Once our model's $\psi$ and $\lambda$ parameters are estimated (Section \ref{estim}), we use Bayes' theorem to compute our main probability of interest: the posterior probability that *Paranthropus* was truly absent at the $i$th site (i.e., $Z_i = 0$), given the estimated parameters and data.
This probability equals zero for those sites where *Paranthropus* is observed to be present, so we focus on deriving the posterior probability equation for those sites where *Paranthropus* is currently observed to be absent.
Fleshing out Equation \ref{bayes} by including additional data ($n_i$) and the estimated parameters ($\hat{\psi}, \hat{\lambda}$):

\begin{equation}
\begin{aligned}
    P(Z_i = 0 | X_i = 0, n_i, \hat{\psi}, \hat{\lambda}) &= \frac{P(X_i = 0 | Z_i = 0, n_i, \hat{\psi}, \hat{\lambda}) P(Z_i = 0 | n_i, \hat{\psi}, \hat{\lambda})}{P(X_i = 0 | n_i, \hat{\psi}, \hat{\lambda})} \\
               &= \frac{1 \times (1 - \hat{\psi})}{I(X_i = 0) (1 - \hat{\psi}) + f_B(0; n_i, \hat{\lambda}) \hat{\psi}} \\
               &= \frac{(1 - \hat{\psi})}{1 \times (1 - \hat{\psi}) + \frac{\Gamma(1) \Gamma(n_i + 1 + \hat{\lambda})}{\Gamma(n_i + 2 + \hat{\lambda})} \frac{\Gamma(2 + \hat{\lambda})}{\Gamma(1) \Gamma(1 + \hat{\lambda})} \hat{\psi}} \\
               &= \frac{1 - \hat{\psi}}{1 - \hat{\psi} + \frac{(n_i + \hat{\lambda})!}{(n_i + 1 + \hat{\lambda})!} \frac{(1 + \hat{\lambda})!}{\lambda!} \hat{\psi}} \\
               &= \frac{1 - \hat{\psi}}{1 - \hat{\psi} + \frac{1 + \hat{\lambda}}{n_i +1 + \hat{\lambda}} \hat{\psi}}.
\end{aligned}
\label{post_prob}
\end{equation}

In Equation \ref{post_prob} going from Lines 1 to 2, the likelihood, $P(X_i = 0 | Z_i = 0, n_i, \hat{\psi}, \hat{\lambda})$, equals one because the probability that we sample zero *Paranthropus* specimens at a given site where it is truly absent ($Z_i=0$) equals one.
The equation for the prior, $P(Z_i = 0 | n_i, \hat{\psi}, \hat{\lambda})$, is given by Equation \ref{bernoulli}, and the equation for the marginal distribution of the data, $P(X_i = 0 | n_i, \hat{\psi}, \hat{\lambda})$, is given by Equation \ref{P_X}.

With Equation \ref{post_prob}, we plug in our estimated parameters $(\hat{\psi}, \hat{\lambda})$ and data for the $i$th site (i.e., the number of sampled mammalian specimens, $n_i$) into Equation \ref{post_prob} to get our posterior probability of interest.
The complement of this probability---the posterior probability that *Paranthropus* was truly present at a site given the estimated parameters and data---can be calculated as $P(Z_i = 1 | X_i = 0, n_i, \hat{\psi}, \hat{\lambda}) = 1 - P(Z_i = 0 | X_i = 0, n_i, \hat{\psi}, \hat{\lambda})$ (Equation \ref{post_prob}).


## Quantifying uncertainty in the parameter estimates and posterior probabilities

As discussed in the main text, we quantify uncertainty by bootstrapping the data (1,000 iterations).
For each bootstrapped iteration, we first resampled our `r nrow(d)` sites with replacement. 
Next for each resampled site, we resampled with replacement the observed number of sampled *Paranthropus* specimens.
We then estimate the $\psi$ and $\lambda$ parameters, following the protocol outlined in Section \ref{estim}.
Finally, we calculate the posterior probability of *Paranthropus* true absence using the estimated parameters and resampled data (Equation \ref{post_prob}). 
All this is repeated 1,000 times to get sampling distributions for $\hat{\psi}$, $\hat{\lambda}$, and the posterior probability of true absence for each of the `r nrow(d)` sites.
We computed 95% confidence intervals for each sampling distribution using the `quantile` function in `R`.


\section{Model selection} \label{model_select}

To assess our model's goodness of fit and whether it is overly complex (e.g., too many parameters), we compared our model to others using the small-sample, bias-corrected Akaike Information Criterion (AIC~*c*~) [@burnham_model_2002].
The AIC~*c*~ formula is:

\begin{align}
  \mathrm{AIC}_c = -2 \mathrm{log} (L(\hat{\theta})) + 2K \left( \frac{n}{n - K - 1} \right),
  \label{AICc}
\end{align}

where $L(\hat{\theta})$ is the likelihood of the fitted model, $K$ is the number of model parameters, and $n$ is sample size (in our case, the number of sites: `r nrow(d)`).

AIC~*c*~ balances goodness of fit (the likelihood) with model complexity (penalties for extra parameters), and compared to AIC, AIC~*c*~ has an additional correction factor for small sample sizes [@burnham_model_2002].
As sample size increases, AIC~*c*~ converges on the traditional AIC.

Lower scores of AIC~*c*~ indicate better model fit, and to facilitate interpretation of AIC~*c*~ scores, we transform AIC~*c*~ into weights [@burnham_model_2002]:

\begin{align}
  w_i = \frac{\mathrm{exp} (-0.5 \Delta_i)}{\sum_{r = 1}^{R} \mathrm{exp} (-0.5 \Delta_r)}, 
  \label{weights}
\end{align}

where $i$ indicates the $i$th model considered, $\Delta_i$ is the AIC~*c*~ of the $i$th model minus the minimum AIC~*c*~ across all models, and $R$ is the total number of investigated models. 
AIC~*c*~ weights sum to one across all models, and larger weights indicate better model support. 

## Other investigated models

We compared our main zero-inflated beta-binomial model (two parameters: $\psi$, $\lambda$) to four other models:

1. binomial model (one parameter: $p$)
2. beta-binomial model (one parameter: $\lambda$)
3. zero-inflated binomial (two parameters: $\psi$, $p$)
4. zero-inflated beta-binomial with a two-parameter beta distribution (three parameters: $\psi$, $\alpha$, $\beta$).

All models are fit to the observed data using the L-BFGS-B optimization algorithm [@byrd_limited_1995].

### Binomial model

This model has no zero inflation (i.e., no probability point mass on zero), and the *Paranthropus* sampling probability is fixed at a single value, $p$, which does not vary across sites.
The PMF for the model is:

\begin{align}
    P(X_i = x) = {n_i \choose x} p ^ x (1 - p) ^ {n_i - x}.
    \label{binom}
\end{align}

### Beta-binomial model

This model also has no zero inflation and is a binomial model (Equation \ref{binom}), wherein $p$ is allowed to vary across sites as a random effect, according to a monotonic, one-parameter beta distribution: $Beta(1, 1 + \lambda)$.
The model PMF is found in Equation \ref{beta-binom} but is replicated below:

\begin{align}
  P(X_i = x) = {n_i\choose x} \frac{B(x + 1, n_i - x + 1 + \lambda)}{B(1, 1 + \lambda)},
  \label{BB}
\end{align}

where $B$ denotes the beta function.

### Zero-inflated binomial model

This model is equivalent to the binomial model (Equation \ref{binom}) but has an additional probability point mass on zero.
The PMF is:

\begin{align}
  P(X_i = x) = I(x = 0)(1 - \psi) + {n_i \choose x} p ^ x (1 - p) ^ {n_i - x} \psi.
  \label{ZI-binom}
\end{align}

### Zero-inflated beta-binomial model (three parameters)

This model is the most complex and is equivalent to our main model (Equation \ref{P_X}), but the beta distribution for the *Paranthropus* sampling probability has two parameters ($\alpha$, $\beta$) instead of one.
Therefore, the sampling probability distribution is allowed to be non-monotonic. 
The PMF is:

\begin{align}
  P(X_i = x) = I(x = 0)(1 - \psi) + {n_i \choose x} \frac{B(x + \alpha, n_i - x + \beta)}{B(\alpha, \beta)} \psi.
  \label{ZI-BB3}
\end{align}

## AIC~*c*~ results

Table \ref{tab:AIC_res} shows the model selection results.
We excluded results for our most complex model (three-parameter zero-inflated beta-binomial) for reasons described in Section \ref{sim}. 

```{r, echo = FALSE}
res <- readRDS("Results/Model selection results.rds")

res.tab <- data.frame(
  model = c(
    "Binomial",
    "Beta-binomial",
    "Zero-inflated binomial",
    "Zero-inflated beta-binomial (two parameters)"
  ),
  logL = round(res$logL, 2),
  k = res$k,
  AICc = round(res$AICc, 2),
  delta_AICc = round(res$AICc - min(res$AICc), 2),
  w = round(res$AICc_w, 4) 
)

knitr::kable(
  res.tab, 
  row.names = FALSE,
  col.names = c(
    "Model",
    "Log-likelihood",
    "Number of parameters",
    "AIC~*c*~",
    "$\\Delta$AIC~*c*~",
    "AIC~*c*~ weight"),
  caption = "Model selection results using AIC~*c*~. \\label{tab:AIC_res}"
  )
```

Results show that our main model---the zero-inflated beta-binomial with two parameters---fits the data the best. 


\section{Simulations to compare our main model with a more complex one} \label{sim}

When the most complex zero-inflated beta-binomial model (three parameters) is included in the model selection process (Section \ref{model_select}), it has the smallest AIC~*c*~ score (190.68) and the largest AIC~*c*~ weight (0.91).
However, this model's parameter estimates seemed nonsensical to us ($\hat{\psi}$ = 1.0, $\hat{\alpha}$ = 0.2, $\hat{\beta}$ = 56.3).
The $\psi$ estimate in particular implies that *Paranthropus* is truly present at all sites, regardless of whether it's been found yet. 
This contradicts what we know from ecological theory: a species is not present at all sites within its geographic range [@rapaport_areography_1982; @hurlbert_range_2005; @hurlbert_ecol_2007].
Therefore, we conducted simulations to assess how well the three-parameter zero-inflated beta-binomial (ZI-BB3) model estimated known parameter values. 
We repeated this process for our main model: the two-parameter zero-inflated beta-binomial (ZI-BB2).

\subsection{Simulation details} \label{sim_deets}

```{r, echo = FALSE}
model.res <- readRDS("Results/Main model results.rds")
BB2.res <- readRDS("Results/BB2 sim results.rds")
BB3.res <- readRDS("Results/BB3 sim results.rds")
```

For both sets of simulations, simulated $\psi$ values are {`r as.numeric(dimnames(BB2.res)[[1]])`}. 
For the ZI-BB2 model, simulated $\lambda$ values are {`r as.numeric(dimnames(BB2.res)[[2]])`}.
For the ZI-BB3 model, simulated $\alpha$ values are {`r as.numeric(dimnames(BB3.res)[[2]])`} and simulated $\beta$ values are {`r as.numeric(dimnames(BB3.res)[[3]])`}.
We chose small $\alpha$ values due to the small value of $\alpha$ estimated from the data ($\hat{\alpha} = 0.2$). 

We simulate *Paranthropus* abundances across sites, given known parameter values: $\psi$ and $\lambda$ for the ZI-BB2 simulations, and $\psi$, $\alpha$, and $\beta$ for the ZI-BB3 simulations. 
We then estimate these parameters with their corresponding model and compare the estimates to their predetermined values. 
We use the observed number of sites and number of mammalian specimens across sites for the simulations, thereby varying the parameter values only.
We conduct the simulations as follows:

1) To determine at which sites *Paranthropus* was truly absent or present (i.e., $Z_i$), we take a random draw from a Bernoulli distribution, where the number of trials is the number of sites, and the probability of success (i.e., *Paranthropus* is present) is the prespecified value of $\psi$. 
The output is a vector of 0s and 1s, where the length of the vector is the total number of sites, 0 denotes true *Paranthropus* absence, 1 denotes true *Paranthropus* presence, and the proportion of 1s equals $\psi$ on average. 

2) For those sites that have *Paranthropus* (i.e., $Z_i = 1$), we simulate *Paranthropus* abundances (i.e., $X_i$) as a random draw from the beta-binomial distribution, given the observed number of mammalian specimens at each site and either a prespecified $\lambda$ value (Equation \ref{beta-binom}) or prespecified $\alpha$ and $\beta$ values (right-hand side of plus sign in Equation \ref{ZI-BB3}, without the $\psi$). 
We do this using the `rbetabinom` function in the `rmutil` package [@R-rmutil].
For those simulated iterations that resulted in zero *Paranthropus* specimens across all sites, we re-ran simulations until there was at least one *Paranthropus* specimen across all sites.

3) The appropriate zero-inflated beta-binomial model is fit to the simulated data, generating parameter estimates. 

4) Steps 1--3 are iterated `r length(dimnames(BB2.res)[[3]])` times, yielding `r length(dimnames(BB2.res)[[3]])` estimates of each parameter.

## Simulation results

### Two-parameter, zero-inflated beta-binomial model (ZI-BB2)

Figure \ref{fig:ZI-BB2_psi} shows that the ZI-BB2 model produces unbiased estimates of $\psi$ at all simulated values of $\psi$ and $\lambda$.
The variation around $\hat{\psi}$---when considered across all values of $\lambda$---is at its maximum when $\psi = 0.5$.
For a given simulated iteration of 0s and 1s determining *Paranthropus* true absence or presence at sites (i.e., $Z_i$) (see Step 1 in Section \ref{sim_deets}), the number of 1s follows a binomial distribution.
It is known that the variance of a binomial random variable is at its maximum when the probability of success equals 0.5, so this likely explains the increased variation of $\hat{\psi}$ when $\psi = 0.5$.

The variation around $\hat{\psi}$ also increases as $\lambda$ increases (Figure \ref{fig:ZI-BB2_psi}).
This is due to larger values of $\lambda$ concentrating more of the sampling probability density function ($p_i$) at smaller values (Figure \ref{fig:beta_dist}).
As such, simulations with large $\lambda$ produce more zero *Paranthropus* specimens across sites, even when *Paranthropus* is truly present (i.e., false absences).
The model 'struggles' to distinguish between true and false absences, leading to greater variation around $\hat{\psi}$. 
Indeed, we see this problem is at its worst when $\psi = 0.1$ and $\lambda = 200$ (Figure \ref{fig:ZI-BB2_psi}).
These are the parameter values that would produce the most zero *Paranthropus* specimens: small $\psi$ means more true absences and large $\lambda$ means more false absences. 

```{r, echo = FALSE}
# get out simulation parameters
psi.sim <- as.numeric(dimnames(BB2.res)[[1]])
lambda.sim <- as.numeric(dimnames(BB2.res)[[2]])
n.iter <- dim(BB2.res)[3]
param <- dimnames(BB2.res)[[4]]

# number of different combinations of parameter estimates
BB2.nrow <- prod(dim(BB2.res))

# create empty data frame
BB2.sim <- data.frame(
  estimate = rep(NA, BB2.nrow),
  parameter = rep(NA, BB2.nrow),
  psi = rep(NA, BB2.nrow),
  lambda = rep(NA, BB2.nrow)
)

# fill out parameter column
BB2.sim$parameter <- rep(param, each = n.iter)

# get all combinations of psi & lambda
param.comb <- expand.grid(psi.sim, lambda.sim)

# fill out psi & lambda column
BB2.sim[, c("psi", "lambda")] <- 
  param.comb[
    rep(
      seq_len(nrow(param.comb)), 
      times = n.iter
      ), 
    ]

# fill out estimates column
for(psi_i in seq_along(psi.sim)){
  for(lambda_i in seq_along(lambda.sim)){
    for(j in seq_along(param)){
      
      BB2.sim$estimate[
        BB2.sim$parameter == param[j] &
        BB2.sim$psi == psi.sim[psi_i] & 
        BB2.sim$lambda == lambda.sim[lambda_i]
      ] <- BB2.res[psi_i, lambda_i, , j]
    }
  }
}
```

```{r, echo = FALSE, warning = FALSE, fig.height = 8, cache = TRUE, fig.cap = "Simulation results showing the two-parameter, zero-inflated beta-binomial model's ability to estimate $\\psi$ for various values of $\\psi$ and $\\lambda$. The horizontal dashed lines indicate true values of $\\psi$, while the diamonds indicate the average estimated $\\psi$ values. \\label{fig:ZI-BB2_psi}"}
# load ggplot
library(ggplot2)

# psi_hat plot
BB2.sim.psi <- BB2.sim[BB2.sim$parameter == "psi_hat", ]

## change facet labels
psi_labs <- paste("True psi =", psi.sim)
names(psi_labs) <- psi.sim

## create plot
ggplot(BB2.sim.psi, aes(x = factor(lambda), y = estimate)) + 
  geom_violin(trim = FALSE, fill = "lightpink1") +
  stat_summary(
    fun.y = mean, 
    geom = "point", 
    shape = 23, 
    size = 2) +
  facet_wrap(
    ~psi, 
    ncol = 2, 
    labeller = labeller(psi = psi_labs)) +
  geom_hline(
    data = BB2.sim.psi, 
    aes(yintercept = psi), 
    linetype = "dashed") + 
  theme_bw() +
  labs(
    x = expression("True lambda (" * lambda * ")"),
    y = expression("Estimated psi (" * hat(psi) * ")")) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    strip.text = element_text(size = 12))
```

```{r echo=FALSE, fig.height=8, warning=FALSE, cache = TRUE, fig.cap = "Simulation results showing the two-parameter, zero-inflated beta-binomial model's ability to estimate $\\lambda$ for various values of $\\psi$ and $\\lambda$. The horizontal dashed lines indicate true values of $\\lambda$, while the diamonds indicate the average estimated $\\lambda$ values. \\label{fig:ZI-BB2_lambda}"}
# lambda_hat plot
BB2.sim.lambda <- BB2.sim[BB2.sim$parameter == "lambda_hat", ]

## change facet labels
lambda_labs <- paste("True lambda =", lambda.sim)
names(lambda_labs) <- lambda.sim

## create plot
ggplot(BB2.sim.lambda, aes(x = factor(psi), y = estimate)) + 
  geom_violin(trim = FALSE, fill = "lightskyblue1") +
  stat_summary(
    fun.y = mean, 
    geom = "point", 
    shape = 23, 
    size = 2) +
  facet_wrap(
    ~lambda, 
    ncol = 2, 
    labeller = labeller(lambda = lambda_labs),
    scales = "free_y") +
  geom_hline(
    data = BB2.sim.lambda, 
    aes(yintercept = lambda), 
    linetype = "dashed") + 
  theme_bw() +
  labs(
    x = expression("True psi (" * psi * ")"),
    y = expression("Estimated lambda (" * hat(lambda) * ")")) +
  scale_y_log10() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    strip.text = element_text(size = 12))
```

Figure \ref{fig:ZI-BB2_lambda} shows that the model produces unbiased estimates of $\lambda$ at most values of simulated $\psi$ and $\lambda$; there is a slight positive bias in $\hat{\lambda}$ when $\psi = 0.1$ (+`r round(mean(BB2.sim.lambda$estimate[BB2.sim.lambda$psi == 0.1] - BB2.sim.lambda$lambda[BB2.sim.lambda$psi == 0.1], na.rm = T))` when averaged across all values of $\lambda$). 
Such a low value for $\psi$ means that *Paranthropus* is simulated to be truly absent at most sites.
The positive bias in $\lambda$ suggests that the model is confusing true absences for false ones: the model is identifying many of the observed zeros as false absences and is estimating a larger $\lambda$ (Figure \ref{fig:beta_dist}) to account for these unsampled presences.
This phenomenon also explains why the variation around $\hat{\lambda}$ increases as $\psi$ decreases. 

All in all, the ZI-BB2 model performs well when the simulated parameter values are near their counterparts, as estimated from the data ($\hat{\psi}$ = `r round(model.res$estim.param[1], 2)`, $\hat{\lambda}$ = `r round(model.res$estim.param[2])`).

### Three-parameter, zero-inflated beta-binomial model (ZI-BB3)

Simulation results show that almost all ZI-BB3 parameter estimates are biased (Figures \ref{fig:ZI-BB3_psi_alpha}--\ref{fig:ZI-BB3_beta_alpha}).
For $\hat{\psi}$, this bias is proximately caused by the bimodal nature of its sampling distribution: one mode is located at 1.0, while the other is located near $\psi$'s true value (Figures \ref{fig:ZI-BB3_psi_alpha} & \ref{fig:ZI-BB3_psi_beta}) (the bimodal sampling distribution of $\hat{\psi}$, or any parameter, indicates the existence of local optima in the likelihood function).
The magnitude of $\hat{\psi}$'s bias is directly related to the number of simulated iterations where $\hat{\psi} = 1.0$ (Figures \ref{fig:ZI-BB3_psi_alpha} & \ref{fig:ZI-BB3_psi_beta}).
The number of simulated iterations where $\hat{\psi} = 1.0$ is itself caused by those iterations where there are many simulated zeros, i.e., zero *Paranthropus* specimens across sites ($X_i = 0$ for most sites).
Many simulated zeros occur when $\psi$ is smaller, which produces more true absences across sites, and when $\alpha$ is smaller and $\beta$ is larger, which produces more false absences across sites (e.g., expected *Paranthropus* sampling probability, $E(p_i)$, equals $\alpha / (\alpha + \beta)$); these parameter values cause the greatest degree of bias in $\hat{\psi}$ (Figures \ref{fig:ZI-BB3_psi_alpha} & \ref{fig:ZI-BB3_psi_beta}).
With lots of simulated zeros across sites, the model sometimes interprets *all* zeros, incorrectly, as false absences: $\hat{\psi} = 1.0$ implies that *Paranthropus* is truly present at *all* sites, and the false absences are modeled with smaller $\hat{\alpha}$ and larger $\hat{\beta}$. 
This phenomenon also explains the sampling distribution modes at $\hat{\alpha} < 0.1$ (Figures \ref{fig:ZI-BB3_alpha_psi} & \ref{fig:ZI-BB3_alpha_beta}) and $\hat{\beta} > 10,000$ (Figures \ref{fig:ZI-BB3_beta_psi} & \ref{fig:ZI-BB3_beta_alpha}) when $\psi$ is small, $\alpha$ is small, and $\beta$ is large. 
When $\psi$ is larger (i.e., 0.7 or 0.9), those parameter values that generate more false absences (smaller $\alpha$ and larger $\beta$) create more variation in $\hat{\psi}$, which 'pulls' $\hat{\psi}$ away from 1.0 and generates a negative bias (Figures \ref{fig:ZI-BB3_psi_alpha} & \ref{fig:ZI-BB3_psi_beta}). 

All estimated $\alpha$ and $\beta$ values are biased upwards (Figures \ref{fig:ZI-BB3_alpha_psi}--\ref{fig:ZI-BB3_beta_alpha}). 
The magnitude of these biases are larger when $\psi$ is smaller, $\alpha$ is smaller, and $\beta$ is larger, i.e., those parameter values that generate many simulated zeros across sites.
These zeros 'confuse' the ZI-BB3 model, which sometimes treats the zeros as false absences (i.e., smaller $\hat{\alpha}$ and larger $\hat{\beta}$) or true absences (i.e., larger $\hat{\alpha}$ and $\hat{\beta}$ values).
It is these larger $\hat{\alpha}$ and $\hat{\beta}$ values---which still result in small expected *Paranthropus* sampling probabilities (on average, ~0.005)---that generate the long, positive tails in these sampling distributions (Figures \ref{fig:ZI-BB3_alpha_psi}--\ref{fig:ZI-BB3_beta_alpha}); this in turn drives the positive bias in these parameter estimates. 

In sum, the biased parameter estimates of the ZI-BB3 model indicate that the model is misspecified and overly complex (i.e., too many parameters).
Regarding $\hat{\psi}$, the erroneous sampling distribution modes at 1.0 (Figures \ref{fig:ZI-BB3_psi_alpha} & \ref{fig:ZI-BB3_psi_beta}) indicate that the result of $\hat{\psi} = 1.0$ when the ZI-BB3 model is fit to the data is also incorrect.
This suggests that the $\alpha$ and $\beta$ estimates are also biased and incorrect.
As such, we view the ZI-BB3 model as inappropriate for our data, and we do not consider it any further.

```{r, echo = FALSE, cache = TRUE}
# Read in simulation results
BB3.sim.res <- readRDS("Results/BB3 sim results.rds")

# get out simulation parameters
psi.sim <- as.numeric(dimnames(BB3.sim.res)[[1]])
alpha.sim <- as.numeric(dimnames(BB3.sim.res)[[2]])
beta.sim <- as.numeric(dimnames(BB3.sim.res)[[3]])
n.iter <- dim(BB3.sim.res)[4]
param <- dimnames(BB3.sim.res)[[5]]

# number of different combinations of parameter estimates
BB3.nrow <- prod(dim(BB3.sim.res))

# create empty data frame
BB3.sim <- data.frame(
  estimate = rep(NA, BB3.nrow),
  parameter = rep(NA, BB3.nrow),
  psi = rep(NA, BB3.nrow),
  A = rep(NA, BB3.nrow),
  B = rep(NA, BB3.nrow)
)

# fill out parameter column
BB3.sim$parameter <- rep(param, each = BB3.nrow / length(param))

# get all combinations of psi, alpha, & beta
param.comb <- expand.grid(
  psi.sim, 
  alpha.sim, 
  beta.sim)

# fill out psi, alpha, & beta column
BB3.sim[, c("psi", "A", "B")] <- 
  param.comb[
    rep(
      seq_len(nrow(param.comb)), 
      times = n.iter
    ), 
  ]

# fill out estimates column
for(psi_i in seq_along(psi.sim)){
  for(alpha_i in seq_along(alpha.sim)){
    for(beta_i in seq_along(beta.sim)){
      for(j in seq_along(param)){
        
        BB3.sim$estimate[
          BB3.sim$parameter == param[j] &
          BB3.sim$psi == psi.sim[psi_i] & 
          BB3.sim$A == alpha.sim[alpha_i] &
          BB3.sim$B == beta.sim[beta_i]
        ] <- BB3.sim.res[psi_i, alpha_i, beta_i, , j]
      }
    }
  }
}
```

```{r, echo = FALSE, warning = FALSE, fig.height = 8, cache = TRUE, fig.cap = "Simulation results showing the three-parameter, zero-inflated beta-binomial model's ability to estimate $\\psi$ for various values of $\\psi$ and $\\alpha$. The horizontal dashed lines indicate true values of $\\psi$, while the diamonds indicate the average estimated $\\psi$ values. \\label{fig:ZI-BB3_psi_alpha}"}
# psi_hat plot
BB3.sim.psi <- BB3.sim[BB3.sim$parameter == "psi_hat", ]

## change facet labels
psi_labs <- paste("True psi =", psi.sim)
names(psi_labs) <- psi.sim

## create plot
### psi ~ alpha
ggplot(BB3.sim.psi, aes(x = factor(A), y = estimate)) + 
  geom_violin(trim = FALSE, fill = "lightpink1") +
  stat_summary(
    fun.y = mean, 
    geom = "point", 
    shape = 23, 
    size = 2) +
  facet_wrap(
    ~psi, 
    ncol = 2, 
    labeller = labeller(psi = psi_labs)) +
  geom_hline(
    data = BB3.sim.psi, 
    aes(yintercept = psi), 
    linetype = "dashed") + 
  theme_bw() +
  labs(
    x = expression("True alpha (" * alpha * ")"),
    y = expression("Estimated psi (" * hat(psi) * ")")) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    strip.text = element_text(size = 12))
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE, fig.height = 8, fig.cap = "Simulation results showing the three-parameter, zero-inflated beta-binomial model's ability to estimate $\\psi$ for various values of $\\psi$ and $\\beta$. The horizontal dashed lines indicate true values of $\\psi$, while the diamonds indicate the average estimated $\\psi$ values. \\label{fig:ZI-BB3_psi_beta}"}
### psi ~ beta
ggplot(BB3.sim.psi, aes(x = factor(B), y = estimate)) + 
  geom_violin(trim = FALSE, fill = "lightpink3") +
  stat_summary(
    fun.y = mean, 
    geom = "point", 
    shape = 23, 
    size = 2) +
  facet_wrap(
    ~psi, 
    ncol = 2, 
    labeller = labeller(psi = psi_labs)) +
  geom_hline(
    data = BB3.sim.psi, 
    aes(yintercept = psi), 
    linetype = "dashed") + 
  theme_bw() +
  labs(
    x = expression("True beta (" * beta * ")"),
    y = expression("Estimated psi (" * hat(psi) * ")")) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    strip.text = element_text(size = 12))
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE, fig.height = 8, fig.cap = "Simulation results showing the three-parameter, zero-inflated beta-binomial model's ability to estimate $\\alpha$ for various values of $\\alpha$ and $\\psi$. The horizontal dashed lines indicate true values of $\\alpha$, while the diamonds indicate the average estimated $\\alpha$ values. \\label{fig:ZI-BB3_alpha_psi}"}
# alpha_hat plot
BB3.sim.alpha <- BB3.sim[BB3.sim$parameter == "alpha_hat", ]

## change facet labels
alpha_labs <- paste("True alpha =", alpha.sim)
names(alpha_labs) <- alpha.sim

## create plot
### alpha ~ psi
ggplot(BB3.sim.alpha, aes(x = factor(psi), y = estimate)) + 
  geom_violin(trim = FALSE, fill = "seagreen1") +
  stat_summary(
    fun.y = mean, 
    geom = "point", 
    shape = 23, 
    size = 2) +
  facet_wrap(
    ~A, 
    ncol = 2, 
    labeller = labeller(A = alpha_labs)) +
  geom_hline(
    data = BB3.sim.alpha, 
    aes(yintercept = A), 
    linetype = "dashed") + 
  scale_y_log10() + 
  theme_bw() +
  labs(
    x = expression("True psi (" * psi * ")"),
    y = expression("Estimated alpha (" * hat(alpha) * ")")) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    strip.text = element_text(size = 12))
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE, fig.height = 8, fig.cap = "Simulation results showing the three-parameter, zero-inflated beta-binomial model's ability to estimate $\\alpha$ for various values of $\\alpha$ and $\\beta$. The horizontal dashed lines indicate true values of $\\alpha$, while the diamonds indicate the average estimated $\\alpha$ values. \\label{fig:ZI-BB3_alpha_beta}"}
### alpha ~ beta
ggplot(BB3.sim.alpha, aes(x = factor(B), y = estimate)) + 
  geom_violin(trim = FALSE, fill = "seagreen3") +
  stat_summary(
    fun.y = mean, 
    geom = "point", 
    shape = 23, 
    size = 2) +
  facet_wrap(
    ~A, 
    ncol = 2, 
    labeller = labeller(A = alpha_labs)) +
  geom_hline(
    data = BB3.sim.alpha, 
    aes(yintercept = A), 
    linetype = "dashed") + 
  scale_y_log10() +
  theme_bw() +
  labs(
    x = expression("True beta (" * beta * ")"),
    y = expression("Estimated alpha (" * hat(alpha) * ")")) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    strip.text = element_text(size = 12))
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE, fig.height = 8, fig.cap = "Simulation results showing the three-parameter, zero-inflated beta-binomial model's ability to estimate $\\beta$ for various values of $\\beta$ and $\\psi$. The horizontal dashed lines indicate true values of $\\beta$, while the diamonds indicate the average estimated $\\beta$ values. \\label{fig:ZI-BB3_beta_psi}"}
# beta_hat plot
BB3.sim.beta <- BB3.sim[BB3.sim$parameter == "beta_hat", ]

## change facet labels
beta_labs <- paste("True beta =", beta.sim)
names(beta_labs) <- beta.sim

## create plot
### beta ~ psi
ggplot(BB3.sim.beta, aes(x = factor(psi), y = estimate)) + 
  geom_violin(trim = FALSE, fill = "mediumpurple1") +
  stat_summary(
    fun.y = mean, 
    geom = "point", 
    shape = 23, 
    size = 2) +
  facet_wrap(
    ~B, 
    ncol = 2, 
    labeller = labeller(B = beta_labs),
    scales = "free_y") +
  geom_hline(
    data = BB3.sim.beta, 
    aes(yintercept = B), 
    linetype = "dashed") + 
  scale_y_log10() +
  theme_bw() +
  labs(
    x = expression("True psi (" * psi * ")"),
    y = expression("Estimated beta (" * hat(beta) * ")")) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    strip.text = element_text(size = 12))
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE, fig.height = 8, fig.cap = "Simulation results showing the three-parameter, zero-inflated beta-binomial model's ability to estimate $\\beta$ for various values of $\\beta$ and $\\alpha$. The horizontal dashed lines indicate true values of $\\beta$, while the diamonds indicate the average estimated $\\beta$ values. \\label{fig:ZI-BB3_beta_alpha}"}
### beta ~ alpha
ggplot(BB3.sim.beta, aes(x = factor(A), y = estimate)) + 
  geom_violin(trim = FALSE, fill = "mediumpurple3") +
  stat_summary(
    fun.y = mean, 
    geom = "point", 
    shape = 23, 
    size = 2) +
  facet_wrap(
    ~B, 
    ncol = 2, 
    labeller = labeller(B = beta_labs),
    scales = "free_y") +
  geom_hline(
    data = BB3.sim.beta, 
    aes(yintercept = B), 
    linetype = "dashed") + 
  scale_y_log10() +
  theme_bw() +
  labs(
    x = expression("True alpha (" * alpha * ")"),
    y = expression("Estimated beta (" * hat(beta) * ")")) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    strip.text = element_text(size = 12))
```

# Assessing model assumptions

Our model makes two assumptions regarding data independence:

1) Site data are independent from each other.
2) Within sites, specimen data are independent from each other.

## Assumption #1: independence of site data

### Regarding $\psi$

Regarding assumption #1 in estimating $\psi$, this would be violated if true *Paranthropus* presence/absence is spatiotemporally autocorrelated across sites. 
That is, sites that are closer together in space and/or time are more likely to exhibit the same state of *Paranthropus* presence/absence (e.g., closer sites all have *Paranthropus* present). 
To assess this assumption, we first take observed *Paranthropus* presence/absence data across sites and assume that they reflect true presence/absence. 
We know that this is strictly not true as an observed absence can reflect an unsampled presence (after all, this is the general problem we are trying to address), but it can also be reasonably assumed that observed presence/absence is more reflective of true presence/absence, rather than complete noise. 
We then consider all pairwise comparisons of sites in terms of (1) whether their observed *Paranthropus* presence/absence states match (1 = match, 0 = otherwise) and (2) their temporal and spatial distances from each other. 
We finally use multiple logistic regression to model (1) as a function of (2) with an interaction term between temporal and spatial distance (after centering and scaling the independent variables) to see if sites that are closer together in time and/or space are more likely to exhibit the same observed *Paranthropus* presence/absence state.

```{r, echo = FALSE}
# define objects
x <- d$Paran_nisp
n <- x + d$NonParanMamm_nisp
rel.abund <- x / n

# calculate distances between sites
RA.dist <- dist(rel.abund) # relative abundance

PA <- as.numeric(x != 0) # presence = 1, absence = 0
PA.dist <- dist(PA) # presence absence
# invert zeros and ones so 1 indicates a match, 0 otherwise
PA.dist1 <- PA.dist 
PA.dist1[PA.dist == 0] <- 1
PA.dist1[PA.dist == 1] <- 0

time.dist <- dist(d$MeanAge_Ma) # time

spatial.dist <- dist(d[, c("Latitude", "Longitude")]) # space
```

```{r, echo = FALSE}
glm.PA <- glm(PA.dist1 ~ scale(c(time.dist)) * scale(c(spatial.dist)), family = "binomial")

lm.rel.abund <- lm(RA.dist ~ scale(c(time.dist)) * scale(c(spatial.dist)))

lm.df <- data.frame(glm.PA$coefficients, lm.rel.abund$coefficients)

rownames(lm.df) <- c("Intercept", "scale(temporal distance)", "scale(spatial distance)", "Interaction term")
colnames(lm.df) <- c("Presence-absence logistic regression", "Relative abundance OLS")
```

Table \ref{tab:lm_tab} shows that the logistic regression coefficient estimates are all small. 
We will not discuss the interaction term given its negligible magnitude (indeed, coefficient estimates are virtually identical when no interaction term is included). 
Firstly, the coefficient estimates are expected to be negative: an increase in spatial and/or temporal distance between sites should lead to differences in *Paranthropus* presence/absence states (i.e., *Paranthropus* is present at one site but absent at the other); recall that we coded different states as 0s, while matches are 1s.
We can exponentiate the logistic regression coefficients to make them more interpretable using the language of odds.
Odds are defined, in our case, as the probability of *Paranthropus* presence/absence states matching divided by the probability that they do not match.
Therefore, an odds of 2.0 means that it is twice as likely that *Paranthropus* presence/absence states will match rather than not.
When exponentiated, the intercept is `r round(exp(glm.PA$coefficients[1]), 2)`, meaning that the probability of *Paranthropus* states matching is only `r (round(exp(glm.PA$coefficients[1]), 2) - 1) * 100`% more likely than them not matching when the independent variables are set to zero (zero values in our case indicate the average pairwise temporal and spatial distance in our dataset because we centered the variables prior to analysis). 
The exponentiated coefficients for "scale(temporal distance)" and "scale(spatial distance)" are `r round(exp(glm.PA$coefficients[2]), 2)` and `r round(exp(glm.PA$coefficients[3]), 2)`, respectively. 
Thus, when holding spatial distance constant, a one standard deviation increase in temporal distance results in a `r abs(1 - round(exp(glm.PA$coefficients[2]), 2)) * 100`% *increase* in the odds of *Paranthropus* presence/absence states matching, opposite the direction we would expect. 
Holding temporal distance constant, a one standard deviation increase in spatial distance leads to a `r abs(1 - round(exp(glm.PA$coefficients[3]), 2)) * 100`% decrease in the odds of *Paranthropus* presence/absence states matching. 
This translates to a decrease in odds from `r round(exp(glm.PA$coefficients[1]), 2)` to `r round(exp(glm.PA$coefficients[1]) * exp(glm.PA$coefficients[3]), 2)` when the variable "scale(spatial distance)" increases from 0 to 1 (while holding temporal distance constant).
However, because we centered and scaled the data prior to analysis, this unit increase is quite substantial (Figure \ref{fig:spat_dist}).
In sum, there appears to be no temporal autocorrelation in *Paranthropus* presence/absence states, but there might be some very slight spatial autocorrelation.

```{r, echo = FALSE, fig.cap = "Histogram of the centered and scaled spatial distances between every pairwise combination of sites. Centering the data results in a mean of zero, while scaling transforms the data into standard deviation units. \\label{fig:spat_dist}"}
hist(scale(spatial.dist), xlab = "scale(spatial distance)", ylab = "Numbers of pairs of sites", col = "gray", main = "")
```

### Regarding $\lambda$

Regarding assumption #1 in estimating $\lambda$, this would be violated if *Paranthropus* sampling probability is spatiotemporally autocorrelated across sites. 
That is, sites that are closer together in space and/or time are more likely to have similar *Paranthropus* sampling probability values. 
As mentioned in the main text, *Paranthropus* sampling probability at site $i$ can be equated to its observed relative abundance at that site.
We consider all pairwise comparisons of sites in terms of their (1) differences in observed *Paranthropus* relative abundance and (2) temporal and spatial distances from each other. 
As with the the presence/absence logistic regression, we model (1) as a function of (2) with an interaction between the centered and scaled independent variables, but this time using multiple ordinary least squares regression.
Again, the goal is to assess whether sites that are closer together in time and/or space are more similar in their observed *Paranthropus* relative abundances.

Table \ref{tab:lm_tab} shows that all regression coefficients are small, and the multiple $R^2$ of the entire model is only `r round(summary(lm.rel.abund)$r.squared, 2)`. 
Considering all pairwise comparisons between sites, Figure \ref{fig:autocorr} plots observed *Paranthropus* relative abundance differences as a function of temporal (Figure \ref{fig:autocorr}A) or spatial (Figure \ref{fig:autocorr}B) distances. 
We expect the relationships to be positive, where sites that are further away temporally or spatially are expected to have more dissimilar relative abundance values. 
The observed relationships are in fact *negative* (Figure \ref{fig:autocorr}), opposite the expected direction.
Therefore, it appears that observed *Paranthropus* relative abundances across sites are not spatiotemporally autocorrelated. 

\  

```{r, echo = FALSE}
knitr::kable(round(lm.df, 3), caption = "Coefficient estimates for the multiple logistic (presence-absence) and multiple ordinary least squares (relative abundance) regression models. \"scale\" indicates that these independent variables were centered and scaled prior to fitting the models. \\label{tab:lm_tab}")
```

```{r, echo = FALSE, fig.cap = "Scatter plots of observed *Paranthropus* relative abundance differences as a function of (A) temporal distance and (B) spatial distance for all pairwise comparisons of sites. $\\rho$ is the Spearman's rank correlation coefficient. \\label{fig:autocorr}"}
par(mfrow = c(1, 2), mar = c(5, 4, 4, 0) + 0.1)

plot(time.dist, RA.dist, main = "", xlab = "Temporal distance (millions of years)", ylab = expression(italic(Paranthropus) ~ "relative abundance difference"), cex.axis = 0.8, cex.lab = 0.8)

mtext("A", at = 0, cex = 1.5)

cor.time <- round(cor(time.dist, RA.dist, method = "spearman"), 2)

text(1.25, 0.05, bquote(rho == .(cor.time)), pos = 4, cex = 1.2)


plot(spatial.dist, RA.dist, main = "", xlab = "Spatial distance\n(Euclidean distance using lat/long)", ylab = "", cex.axis = 0.8, cex.lab = 0.8)

mtext("B", at = 0, cex = 1.5)

cor.space <- round(cor(spatial.dist, RA.dist, method = "spearman"), 2)

text(12, 0.05, bquote(rho == .(cor.space)), pos = 4, cex = 1.2)
```

\  

It should be noted that our models exhibit negligible multicollinearity: the Spearman's rank correlation between temporal and spatial distance between pairs of sites is only $\rho = `r round(cor(spatial.dist, time.dist, method = "spearman"), 2)`$.

## Assumption #2: independence of specimen data

```{r, echo = FALSE}
### get frequency distribution of NISP within individuals for databases

## Laetoli
laetoli <- read.csv("C:/Users/adu/OneDrive - Colostate/Desktop/Manuscripts/Du & Alemseged 2019_Paranthropus afar/Databases/eppe_1998-2005_200329_.csv", header = TRUE)

# subset out certain taxa
laetoli <- laetoli[laetoli$class == "Mammalia" &
                     laetoli$order != "" &
                     laetoli$order != "Lagomorpha" & 
                     laetoli$order != "Rodentia" &
                     laetoli$order != "Insectivora" &
                     laetoli$order != "Stylommatophora", ] # get out large mammals ID'ed to order

laetoli <- laetoli[!(laetoli$order == "Primates" &
                       laetoli$family == ""), ] # remove primate indet.

# subset out beds
laetoli.beds <- c("Ndolanya Beds, Upper Unit", 
                  "Naibadad Beds", 
                  "Ngaloba Beds, Lower Unit")

# get number of individuals per NISP
laetoli.counts <- lapply(laetoli.beds, function(bed) laetoli$organism_quantity[laetoli$bed == bed])

names(laetoli.counts) <- laetoli.beds

## Turkana
turkana <- read.csv("C:/Users/adu/OneDrive - Colostate/Desktop/Manuscripts/Du & Alemseged 2019_Paranthropus afar/Databases/Turkana v47 pruned for Andrew Du.csv", header = TRUE)

turkana$Member[grep("Lomekwi", turkana$Member)] <- "Lomekwi"

# get out members of interest
turk.mbr <- c("Upper Burgi", 
              "KBS", 
              "Okote", 
              "Chari", 
              "Lomekwi", 
              "Lokalalei", 
              "Kalochoro", 
              "Kaitio", 
              "Natoo", 
              "Nariokotome")

turkana <- turkana[turkana$Member %in% turk.mbr, ]

# remove micromammals
turk.remove.orders <- c("Lagomorpha", 
                        "Rodentia")
turkana <- turkana[!(turkana$Order %in% turk.remove.orders), ]

# remove primate indet.
turkana <- turkana[!(turkana$Order == "Primates" & turkana$Family == ""),]

# remove hominin indet.
turkana <- turkana[!(turkana$Tribe == "Hominini" & turkana$Genus == ""),]

# get number of individuals per NISP
turk.counts <- sapply(turk.mbr, function(member){
  
  turkana1 <- turkana[turkana$Member == member, ]
  turk.cts <- table(turkana1$SpecimenNumber)
  turk.cts <- turk.cts[turk.cts > 0]
  
  return(table(turk.cts))
})

## Shungura (American & French)
amer <- read.csv("C:/Users/adu/OneDrive - Colostate/Desktop/Manuscripts/Du & Alemseged 2019_Paranthropus afar/Databases/Omo American_corrected using Wood & Leakey 2011.csv", header = TRUE)

french <- read.csv("C:/Users/adu/OneDrive - Colostate/Desktop/Manuscripts/Du & Alemseged 2019_Paranthropus afar/Databases/Omo french_corrected using Wood & Leakey 2011.csv", header = TRUE)

# fix French members
for(i in c(3:8, 10:12)) french$member[french$member == letters[i]] <- LETTERS[i]

# remove certain taxa
remove.gen.french <- c(
  "Aethomys",
  "algae",
  "Australopithecus",
  "aves",
  "aves ?",
  "aves",
  "chelonia",
  "chelonia ?",
  "coprolith",
  "coprolithe",
  "crocodilia",
  "crocodilia ?",
  "crocodilidae",
  "Crocodylus",
  "Cycloderma",
  "cyprinidae",
  "cyprinidae ?",
  "dipodidae",
  "egg",
  "etheria",
  "Euthecodon",
  "fruit",
  "gasteropod",
  "gasteropods",
  "Gen Nov",
  "Geochelone",
  "Grammomys",
  "Heterocephalus",
  "hominidae",
  "indet",
  "INDET",
  "indet (suidae ?)",
  "Jaculus",
  "leporidae",
  "Mastomys",
  "Oenomys",
  "ostrea",
  "Paraxerus",
  "Pelusios",
  "pisces",
  "pisces ",
  "plantae",
  "pottery  frag",
  "pottery frag",
  "python ",
  "reptilia",
  "reptilia ",
  "reptilia ?",
  "rodentia",
  "shell",
  "shells agglomerat",
  "siluriformes",
  "soil sample",
  "stone",
  "STONE",
  "stones",
  "Tatera",
  "Thallomys",
  "Thryonomys",
  "tomistomidae",
  "wood",
  "wood ?",
  "Xerus"
  )

remove.gen.amer <- c(
  "",
  "16 - 18",
  "18 - 44",
  "2 - 39",
  "24 - 33",
  "48g - 48n",
  "65 - 99",
  "Aethomys",
  "Albizia",
  "Amphibia",
  "Anatidae",
  "Anhinga",
  "Anura",
  "Ardea",
  "Arvicanthis",
  "Australopithecus",
  "Aves",
  "Bagridae",
  "Barbus",
  "Bufonidae",
  "Chelonia",
  "Chiroptera",
  "Ciconiidae",
  "Clarias",
  "Clariidae",
  "Clarius",
  "Clarotes",
  "Coleura",
  "Coprolite",
  "Cricetidae",
  "Crocidura",
  "Crocodilidae",
  "Crocodilus",
  "Cut Bone",
  "Cycloderma",
  "Cyprinidae",
  "DELETED",
  "DISCARDED",
  "Eidolon",
  "EMPTY",
  "Euthecodon",
  "Fossil Fruit",
  "Fossil Wood",
  "Garsinia",
  "Geochelone",
  "Gerbillus",
  "Golunda",
  "Gymnarchus",
  "Heterocephalus",
  "Hipposideros",
  "Hominidae",
  "Hydrocynus",
  "Hydrocyon",
  "Hydrocyonus",
  "Hyperopsius",
  "Indeterminate",
  "Jaculus",
  "Labeo",
  "Lates",
  "Lemniscomys",
  "Lepus",
  "Lost",
  "LOST",
  "Mammalia",
  "Mastomys",
  "Muridae",
  "Murinae",
  "Muroidea",
  "Mus ",
  "Myosorex",
  "No det.",
  "Not assigned",
  "Not Assigned",
  "NOT COLLECTED",
  "Paraxerus",
  "Part of L232-189",
  "PART OF L398-17",
  "PART OF L628-97D",
  "Pebble",
  "Pelomys",
  "Pelusios",
  "Percoidei",
  "Phasianidae",
  "Pisces",
  "Polypterus",
  "Protopterus",
  "Pumice",
  "Quartz Flakes",
  "Quartz Pebble",
  "Ranidae",
  "Reptilia",
  "Rodentia",
  "Saidomys",
  "Serpentes",
  "Shells",
  "Siluriformes",
  "Sindacharax",
  "Sindarcharax",
  "Stone artifact",
  "Stone Artifact",
  "Suncus",
  "Synodontis",
  "Taphozous",
  "Tatera",
  "Thallomys",
  "Thryonomys",
  "Trionichidae",
  "Trionychidae",
  "Trionyx",
  "UNASSIGNED",
  "Xerus"
)

amer <- amer[!(amer$Genus %in% remove.gen.amer), ]

french <- french[!(french$genus %in% remove.gen.french), ]

# subset out members
omo.mbr <- c("C", "D", "E", "F", "G", "H", "J", "K", "L")

amer <- amer[amer$Member %in% omo.mbr, ]

french <- french[french$member %in% omo.mbr, ]

# get counts
amer$Individual.Number <- amer$Individual.Number + 1
amer$Individual.Number[is.na(amer$Individual.Number)] <- 1

amer.counts <- sapply(omo.mbr, function(member){
  
  amer1 <- amer[amer$Member == member, ]
  
  amer.cts <- table(amer1$Individual.Number)
  
  amer.cts <- amer.cts[names(amer.cts) != 2]
  
  amer.cts.rev <- rev(amer.cts)
  
  for(i in seq_along(amer.cts.rev)[-c(length(amer.cts.rev) - 1, length(amer.cts.rev))]){
    
    if(amer.cts.rev[i] > 0) amer.cts.rev[seq(i + 1, length(amer.cts.rev) - 1)] <- amer.cts.rev[seq(i + 1, length(amer.cts.rev) - 1)] - 1
  }
  
  amer.cts.rev[amer.cts.rev < 0] <- 0
  
  amer.cts.rev <- amer.cts.rev[amer.cts.rev > 0]
  
  return(rev(amer.cts.rev))
})

french.counts <- sapply(omo.mbr, function(member){
  
  french.cts <- table(french$specimen.number[french$member == member])
  french.cts <- french.cts[french.cts > 0]
  return(table(french.cts))
})

omo.counts <- vector(mode = "list", length = length(amer.counts))
names(omo.counts) <- names(amer.counts)

for(i in seq_along(omo.counts)){
  
  comb.counts <- c(amer.counts[[i]], french.counts[[i]])
  
  comb.counts1 <- tapply(comb.counts, names(comb.counts), sum)
  
  comb.counts2 <- comb.counts1[order(as.numeric(names(comb.counts1)))]
  
  omo.counts[[i]] <- as.table(comb.counts2)
}
```

Assumption #2 would be violated if multiple specimens belonged to the same individual (e.g., a partial skeleton), and this was the case for a large proportion of specimens at each site. 
Non-independence would artificially inflate the number of independent specimens for each site, which would bias posterior probabilities of absence upwards.
We assessed independence of specimen data for those sites where data on the number of specimens per individual are available (i.e., databases). 
Results show that the majority of individuals at each site are comprised of one specimen (Figure \ref{fig:freq_dist}).
In fact, for each site, the proportion of individuals made up of one specimen exceeds 0.8, except for Member G of the Shungura Formation (`r round(omo.counts$G[1] / sum(omo.counts$G), 2)`) (Figure \ref{fig:prop_one}).
Because all sites in our dataset are taphonomically similar in a general sense (e.g., eastern African large mammalian fossil assemblages that were preserved in fluvio-lacustrine settings and predominantly surface collected), we assume that the dominance of single-specimen individuals is a general pattern that can be extrapolated to those sites not represented in Figures \ref{fig:freq_dist} and \ref{fig:prop_one}.
Thus, given the low proportion of individuals with non-independent specimen data at each site, we view Assumption #2 as not grossly violated, and the estimated posterior probabilities of true absence are robust.  

```{r, echo = FALSE, fig.height = 8.5, fig.cap = "Frequency distributions depicting the number of individuals with a given number of specimens for each site, where those data are available (i.e., databases). \\label{fig:freq_dist}"}

xlimit <- c(1, 80)

par(mfrow = c(8, 3), mar = c(2, 2, 2, 0) + 0.1, oma = c(2, 2, 0, 0))

plot(omo.counts$C, type = "h", main = "Member C (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(omo.counts$D, type = "h", main = "Member D (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(omo.counts$E, type = "h", main = "Member E (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(omo.counts$F, type = "h", main = "Member F (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(omo.counts$G, type = "h", main = "Member G (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(omo.counts$H, type = "h", main = "Member H (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(omo.counts$J, type = "h", main = "Member J (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(omo.counts$K, type = "h", main = "Member K (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(omo.counts$L, type = "h", main = "Member L (Shungura)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Upper Burgi`, type = "h", main = "upper Burgi (Koobi Fora)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`KBS`, type = "h", main = "KBS (Koobi Fora)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Okote`, type = "h", main = "Okote (Koobi Fora)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Chari`, type = "h", main = "Chari (Koobi Fora)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Lomekwi`, type = "h", main = "Lomekwi (Nachukui)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Lokalalei`, type = "h", main = "Lokalalei (Nachukui)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Kalochoro`, type = "h", main = "Kalochoro (Nachukui)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Kaitio`, type = "h", main = "Kaitio (Nachukui)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Natoo`, type = "h", main = "Natoo (Nachukui)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(turk.counts$`Nariokotome`, type = "h", main = "Nariokotome (Nachukui)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(table(laetoli.counts$`Ndolanya Beds, Upper Unit`), type = "h", main = "Upper Ndolanya (Laetoli)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(table(laetoli.counts$`Naibadad Beds`), type = "h", main = "Naibadad (Laetoli)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

plot(table(laetoli.counts$`Ngaloba Beds, Lower Unit`), type = "h", main = "Lower Ngaloba (Laetoli)", xlim = xlimit, xaxt = "n", col = "blue")

axis(1, at = seq(1, 80, 3))

par(mfrow = c(1, 1))

mtext("Number of identified specimens", 1, at = 35, line = 3, cex = 1.25)

mtext("Number of individuals", 2, at = 16, line = 3, cex = 1.25)
```

```{r, echo = FALSE}
sing.prop <- c(
  sapply(laetoli.counts, function(x){
     lae.tab <- table(x)
     return(lae.tab[1] / sum(x))
 }),
 
 sapply(turk.counts, function(x) x[1] / sum(x)),
 
 sapply(omo.counts, function(x) x[1] / sum(x))
)
```

```{r, echo = FALSE, fig.cap = "Histogram of the number of sites with a given proportion of individuals with one specimen. The proportion was calculated for each site as the number of individuals represented by one specimen divided by the total number of individuals. \\label{fig:prop_one}"}

hist(sing.prop, ylab = "Number of sites", xlab = "Proportion of individuals with one specimen", main = "", col = "gray")
```

\newpage

# References